<!DOCTYPE html>
<html lang="ta">
<head>
  <meta charset="UTF-8">
  <title>Blind Navigation ‚Äì Live Object Detection</title>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>

  <!-- COCO-SSD Model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <style>
    body {
      margin: 0;
      background: black;
      overflow: hidden;
    }

    video {
      width: 100vw;
      height: 100vh;
      object-fit: cover;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>

<body>

  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");

    let model;
    let lastMessage = "";

    // üó£Ô∏è Tamil Voice
    function speak(text) {
      if (text === lastMessage) return;
      lastMessage = text;

      window.speechSynthesis.cancel();
      const msg = new SpeechSynthesisUtterance(text);
      msg.lang = "ta-IN";
      msg.rate = 1;
      window.speechSynthesis.speak(msg);
    }

    // üìñ English ‚Üí Tamil mapping
    function toTamil(label) {
      const map = {
        person: "‡ÆÆ‡Æ©‡Æø‡Æ§‡Æ∞‡Øç",
        chair: "‡Æ®‡Ææ‡Æ±‡Øç‡Æï‡Ææ‡Æ≤‡Æø",
        bottle: "‡Æ™‡Ææ‡Æü‡Øç‡Æü‡Æø‡Æ≤‡Øç",
        phone: "‡Æï‡Øà‡Æ™‡Øá‡Æö‡Æø",
        cup: "‡Æï‡Øã‡Æ™‡Øç‡Æ™‡Øà",
        laptop: "‡ÆÆ‡Æü‡Æø‡Æï‡Øç‡Æï‡Æ£‡Æø‡Æ©‡Æø",
        table: "‡ÆÆ‡Øá‡Æö‡Øà",
        book: "‡Æ™‡ØÅ‡Æ§‡Øç‡Æ§‡Æï‡ÆÆ‡Øç"
      };
      return map[label] || label;
    }

    // üì∑ Start Camera
    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
        audio: false
      });

      video.srcObject = stream;

      return new Promise(resolve => {
        video.onloadedmetadata = resolve;
      });
    }

    // ü§ñ Load Model
    async function loadModel() {
      model = await cocoSsd.load();
      speak("‡Æï‡Øá‡ÆÆ‡Æ∞‡Ææ ‡Æ§‡ÆØ‡Ææ‡Æ∞‡Øç. ‡Æö‡ØÅ‡Æ±‡Øç‡Æ±‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ‡Æ±‡ÆÆ‡Øç ‡Æï‡Æ£‡Øç‡Æï‡Ææ‡Æ£‡Æø‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ");
      detectObjects();
    }

    // üëÄ Detect Objects
    async function detectObjects() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const predictions = await model.detect(video);
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (predictions.length > 0) {
        const obj = predictions[0];
        const [x, , w] = obj.bbox;
        const centerX = x + w / 2;
        const screenW = canvas.width;

        let direction = "‡ÆÆ‡ØÅ‡Æ©‡Øç‡Æ©‡Ææ‡Æ≤‡Øç";
        if (centerX < screenW / 3) direction = "‡Æá‡Æü‡Æ™‡Øç‡Æ™‡Æï‡Øç‡Æï‡ÆÆ‡Øç";
        else if (centerX > (2 * screenW) / 3) direction = "‡Æµ‡Æ≤‡Æ™‡Øç‡Æ™‡Æï‡Øç‡Æï‡ÆÆ‡Øç";

        const tamilObject = toTamil(obj.class);
        speak(`${direction} ${tamilObject} ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ`);
      }

      predictions.forEach(p => {
        ctx.strokeStyle = "lime";
        ctx.lineWidth = 3;
        ctx.strokeRect(...p.bbox);

        ctx.fillStyle = "lime";
        ctx.font = "18px Arial";
        ctx.fillText(p.class, p.bbox[0], p.bbox[1] - 5);
      });

      requestAnimationFrame(detectObjects);
    }

    // üöÄ Start Everything
    async function start() {
      await startCamera();
      await loadModel();
    }

    start();
  </script>

</body>
</html>
