<!DOCTYPE html>
<html lang="ta">
<head>
  <meta charset="UTF-8" />
  <title>Blind Navigation - Live Assistant</title>

  <!-- TensorFlow -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <style>
    body {
      margin: 0;
      background: black;
      overflow: hidden;
    }

    video {
      width: 100vw;
      height: 100vh;
      object-fit: cover;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>

<body>

  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");

    let model;
    let lastSpoken = "";

    // ðŸ”Š Tamil voice function
    function speak(text) {
      if (text === lastSpoken) return;
      lastSpoken = text;

      window.speechSynthesis.cancel();
      const msg = new SpeechSynthesisUtterance(text);
      msg.lang = "ta-IN";
      msg.rate = 1;
      window.speechSynthesis.speak(msg);
    }

    // ðŸ“· Camera start
    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
        audio: false
      });

      video.srcObject = stream;

      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve();
      });
    }

    // ðŸ¤– Load AI model
    async function loadModel() {
      model = await cocoSsd.load();
      speak("à®•à¯‡à®®à®°à®¾ à®¤à®¯à®¾à®°à¯. à®µà®´à®¿à®•à®¾à®Ÿà¯à®Ÿà®²à¯ à®¤à¯Šà®Ÿà®™à¯à®•à®¿à®¯à®¤à¯");
      detectObjects();
    }

    // ðŸ‘€ Object detection + navigation logic
    async function detectObjects() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const predictions = await model.detect(video);
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      let command = "à®®à¯à®©à¯à®©à®¾à®²à¯ à®ªà®¾à®¤à¯ˆ à®šà¯à®¤à¯à®¤à®®à®¾à®• à®‰à®³à¯à®³à®¤à¯";

      if (predictions.length > 0) {
        // Take biggest object
        const obj = predictions.reduce((a, b) =>
          a.bbox[2] * a.bbox[3] > b.bbox[2] * b.bbox[3] ? a : b
        );

        const [x, y, width, height] = obj.bbox;
        const centerX = x + width / 2;
        const screenWidth = canvas.width;

        if (centerX < screenWidth / 3) {
          command = "à®‡à®Ÿà®ªà¯à®ªà®•à¯à®•à®®à¯ à®¤à®Ÿà¯ˆà®¯à¯à®³à¯à®³à®¤à¯, à®µà®²à®ªà¯à®ªà®•à¯à®•à®®à¯ à®¨à®•à®°à®µà¯à®®à¯";
        } 
        else if (centerX < (2 * screenWidth) / 3) {
          command = "à®®à¯à®©à¯à®©à®¾à®²à¯ à®¤à®Ÿà¯ˆà®¯à¯à®³à¯à®³à®¤à¯, à®¤à®¯à®µà¯ à®šà¯†à®¯à¯à®¤à¯ à®¨à®¿à®±à¯à®¤à¯à®¤à®µà¯à®®à¯";
        } 
        else {
          command = "à®µà®²à®ªà¯à®ªà®•à¯à®•à®®à¯ à®¤à®Ÿà¯ˆà®¯à¯à®³à¯à®³à®¤à¯, à®‡à®Ÿà®ªà¯à®ªà®•à¯à®•à®®à¯ à®¨à®•à®°à®µà¯à®®à¯";
        }

        // Draw box
        ctx.strokeStyle = "lime";
        ctx.lineWidth = 3;
        ctx.strokeRect(x, y, width, height);

        ctx.fillStyle = "lime";
        ctx.font = "18px Arial";
        ctx.fillText(obj.class, x, y - 5);
      }

      speak(command);
      requestAnimationFrame(detectObjects);
    }

    // ðŸš€ Start everything
    async function start() {
      await startCamera();
      await loadModel();
    }

    start();
  </script>

</body>
</html>
