<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Blind Assistance - Tamil Navigation</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body { margin: 0; background: black; overflow: hidden; }
    video { width: 100vw; height: 100vh; object-fit: cover; }
    canvas { position: absolute; top: 0; left: 0; }
  </style>
</head>
<body>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
let model;

let lastSpokenObjects = [];
let lastSpeakTime = 0;
const speakDelay = 2000; // 2 seconds minimum between messages

// English → Tamil mapping
const tamilNames = {
  person: "மனிதர்",
  chair: "நாற்காலி",
  bottle: "பாட்டில்",
  dog: "நாய்",
  cat: "பூனை",
  tv: "டிவி",
  table: "மேசை",
  laptop: "லேப்டாப்",
  phone: "செல் போன்"
};

// Tamil Voice with repeat control
function speak(objects) {
  const now = Date.now();
  if (now - lastSpeakTime < speakDelay) return; // avoid rapid repeats

  const text = objects.join(", ");
  if (text === lastSpokenObjects.join(", ")) return; // avoid same message

  lastSpokenObjects = objects;
  lastSpeakTime = now;

  const msg = new SpeechSynthesisUtterance("முன்னால் " + text);
  msg.lang = "ta-IN";
  window.speechSynthesis.speak(msg);
}

// Start Camera
async f
